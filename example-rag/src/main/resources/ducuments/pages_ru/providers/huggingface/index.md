# Hugging Face

Один из самых простых способов получить доступ к множеству моделей машинного обучения и искусственного интеллекта — это использование https://huggingface.co/inference-endpoints[Inference Endpoints] от Hugging Face.

Hugging Face Hub — это платформа, которая предоставляет совместную среду для создания и обмена десятками тысяч моделей ML/AI с открытым исходным кодом, наборов данных и демонстрационных приложений.

Inference Endpoints позволяют вам развертывать AI модели на выделенной инфраструктуре с моделью оплаты по мере использования.
Вы можете использовать инфраструктуру, предоставляемую Amazon Web Services, Microsoft Azure и Google Cloud Platform.
Hugging Face позволяет запускать модели на вашем собственном компьютере, но довольно часто не хватает ресурсов CPU/GPU для запуска более крупных, ориентированных на ИИ моделей.

Он предоставляет доступ к недавним (август 2023) моделям Llama 2 и CodeLlama 2 от Meta и предлагает https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard[Open LLM Leaderboard], где вы можете быстро найти качественные модели.

Хотя Hugging Face предлагает бесплатный уровень хостинга, который очень полезен для быстрой оценки того, подходит ли конкретная модель ML/AI для ваших нужд, они не позволяют получить доступ ко многим из этих моделей на бесплатном уровне, используя https://huggingface.co/docs/text-generation-inference/main/en/index[Text Generation Interface API]. Если вы все же хотите перейти в продакшн с надежным API, заплатите несколько центов, чтобы попробовать надежное решение. Цены начинаются от $0.06 за ядро CPU/час и $0.6 за GPU/час.
