# Шаблоны проектирования запросов

Практические реализации техник проектирования запросов на основе всеобъемлющего [Руководства по проектированию запросов](https://www.kaggle.com/whitepaper-prompt-engineering).
Руководство охватывает теорию, принципы и шаблоны эффективного проектирования запросов, в то время как здесь мы демонстрируем, как перевести эти концепции в рабочий Java-код с использованием плавного xref::api/chatclient.adoc[API ChatClient] от Spring AI.
Исходный код демонстрации, использованный в этой статье, доступен по адресу: [Примеры шаблонов проектирования запросов](https://github.com/spring-projects/spring-ai-examples/tree/main/prompt-engineering/prompt-engineering-patterns).

## 1. Конфигурация

Раздел конфигурации описывает, как настроить и откалибровать вашу модель большого языка (LLM) с помощью Spring AI.
Он охватывает выбор подходящего поставщика LLM для вашего случая использования и настройку важных параметров генерации, которые контролируют качество, стиль и формат выходных данных модели.

### Выбор поставщика LLM

Для проектирования запросов вы начнете с выбора модели.
Spring AI поддерживает xref::api/chat/comparison.adoc[несколько поставщиков LLM] (таких как OpenAI, Anthropic, Google Vertex AI, AWS Bedrock, Ollama и другие), позволяя вам переключать поставщиков без изменения кода приложения - просто обновите вашу конфигурацию.
Просто добавьте выбранную стартовую зависимость `spring-ai-starter-model-<MODEL-PROVIDER-NAME>`.
Например, вот как включить API Anthropic Claude:

```xml
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-starter-model-anthropic</artifactId>
</dependency>
```

Вы можете указать имя модели LLM следующим образом:

```java
.options(ChatOptions.builder()
        .model("claude-3-7-sonnet-latest")  // Используйте модель Claude от Anthropic
        .build())
```

Подробную информацию о включении каждой модели можно найти в xref::api/chatmodel.adoc[справочной документации].

### Конфигурация выходных данных LLM

![width=500,float=right](https://docs.spring.io/spring-ai/reference/_images/chat-options-flow.jpg)

Прежде чем углубиться в техники проектирования запросов, важно понять, как настроить поведение выходных данных LLM. Spring AI предоставляет несколько параметров конфигурации, которые позволяют контролировать различные аспекты генерации через сборщик xref::api/chatmodel.adoc#_chat_options[ChatOptions].

Все конфигурации могут быть применены программно, как показано в примерах ниже, или через свойства приложения Spring во время запуска.

#### Температура

Температура контролирует случайность или "креативность" ответа модели.

- **Низкие значения (0.0-0.3)**: Более детерминированные, сосредоточенные ответы. Лучше для фактических вопросов, классификации или задач, где важна последовательность.
- **Средние значения (0.4-0.7)**: Баланс между детерминизмом и креативностью. Хорошо подходит для общих случаев использования.
- **Высокие значения (0.8-1.0)**: Более креативные, разнообразные и потенциально неожиданные ответы. Лучше для креативного письма, мозгового штурма или генерации разнообразных вариантов.

```java
.options(ChatOptions.builder()
        .temperature(0.1)  // Очень детерминированный вывод
        .build())
```

Понимание температуры имеет решающее значение для проектирования запросов, так как разные техники выигрывают от различных настроек температуры.

#### Длина выходных данных (MaxTokens)

Параметр `maxTokens` ограничивает количество токенов (частей слов), которые модель может сгенерировать в своем ответе.

- **Низкие значения (5-25)**: Для отдельных слов, коротких фраз или меток классификации.
- **Средние значения (50-500)**: Для абзацев или коротких объяснений.
- **Высокие значения (1000+)**: Для длинных текстов, рассказов или сложных объяснений.

```java
.options(ChatOptions.builder()
        .maxTokens(250)  // Ответ средней длины
        .build())
```

Установка подходящей длины выходных данных важна для обеспечения получения полных ответов без ненужной многословности.

#### Контроль выборки (Top-K и Top-P)Эти параметры предоставляют вам детальный контроль над процессом выбора токенов во время генерации.

- **Top-K**: Ограничивает выбор токенов K наиболее вероятными следующими токенами. Более высокие значения (например, 40-50) вводят больше разнообразия.
- **Top-P (nucleus sampling)**: Динамически выбирает из наименьшего набора токенов, сумма вероятностей которых превышает P. Значения, такие как 0.8-0.95, являются распространенными.

```java
.options(ChatOptions.builder()
        .topK(40)      // Учитывать только 40 лучших токенов
        .topP(0.8)     // Выбор из токенов, которые покрывают 80% вероятностной массы
        .build())
```

Эти параметры выборки работают в сочетании с температурой для формирования характеристик ответа.

#### Формат структурированного ответа

Вместе с простым текстовым ответом (с использованием `.content()`), Spring AI упрощает прямое сопоставление ответов LLM с объектами Java, используя метод `.entity()`.

```java
enum Sentiment {
    POSITIVE, NEUTRAL, NEGATIVE
}

Sentiment result = chatClient.prompt("...")
        .call()
        .entity(Sentiment.class);
```

Эта функция особенно мощна в сочетании с системными подсказками, которые инструктируют модель возвращать структурированные данные.

#### Опции, специфичные для модели

Хотя переносимый `ChatOptions` предоставляет единый интерфейс для различных поставщиков LLM, Spring AI также предлагает классы опций, специфичных для модели, которые открывают функции и конфигурации, специфичные для поставщика. Эти опции, специфичные для модели, позволяют вам использовать уникальные возможности каждого поставщика LLM.

```java
// Использование опций, специфичных для OpenAI
OpenAiChatOptions openAiOptions = OpenAiChatOptions.builder()
        .model("gpt-4o")
        .temperature(0.2)
        .frequencyPenalty(0.5)      // Параметр, специфичный для OpenAI
        .presencePenalty(0.3)       // Параметр, специфичный для OpenAI
        .responseFormat(new ResponseFormat("json_object"))  // Режим JSON, специфичный для OpenAI
        .seed(42)                   // Определяемая генерация, специфичная для OpenAI
        .build();

String result = chatClient.prompt("...")
        .options(openAiOptions)
        .call()
        .content();

// Использование опций, специфичных для Anthropic
AnthropicChatOptions anthropicOptions = AnthropicChatOptions.builder()
        .model("claude-3-7-sonnet-latest")
        .temperature(0.2)
        .topK(40)                   // Параметр, специфичный для Anthropic
        .thinking(AnthropicApi.ThinkingType.ENABLED, 1000)  // Конфигурация мышления, специфичная для Anthropic
        .build();

String result = chatClient.prompt("...")
        .options(anthropicOptions)
        .call()
        .content();
```

Каждый поставщик модели имеет свою реализацию опций чата (например, `OpenAiChatOptions`, `AnthropicChatOptions`, `MistralAiChatOptions`), которые открывают параметры, специфичные для поставщика, при этом реализуя общий интерфейс. Этот подход дает вам гибкость использовать переносимые опции для совместимости между поставщиками или опции, специфичные для модели, когда вам нужен доступ к уникальным функциям конкретного поставщика.

Обратите внимание, что при использовании опций, специфичных для модели, ваш код становится привязанным к конкретному поставщику, что снижает переносимость. Это компромисс между доступом к продвинутым функциям, специфичным для поставщика, и поддержанием независимости от поставщика в вашем приложении.

## 2. Техники проектирования подсказок

Каждый раздел ниже реализует конкретную технику проектирования подсказок из руководства. Следуя как руководству по "Проектированию подсказок", так и этим реализациям, вы получите полное понимание не только доступных техник проектирования подсказок, но и того, как эффективно их реализовать в производственных Java-приложениях.

### 2.1 Нулевое промптированиеZero-shot prompting включает в себя запрос к ИИ на выполнение задачи без предоставления каких-либо примеров. Этот подход проверяет способность модели понимать и выполнять инструкции с нуля. Большие языковые модели обучены на обширных корпусах текста, что позволяет им понимать, что такие задачи, как "перевод", "резюмирование" или "классификация", подразумевают без явных демонстраций.

Zero-shot идеально подходит для простых задач, где модель, вероятно, видела похожие примеры во время обучения, и когда вы хотите минимизировать длину запроса. Однако производительность может варьироваться в зависимости от сложности задачи и того, насколько хорошо сформулированы инструкции.

```java
// Implementation of Section 2.1: General prompting / zero shot (page 15)
public void pt_zero_shot(ChatClient chatClient) {
    enum Sentiment {
        POSITIVE, NEUTRAL, NEGATIVE
    }

    Sentiment reviewSentiment = chatClient.prompt("""
            Classify movie reviews as POSITIVE, NEUTRAL or NEGATIVE.
            Review: "Her" is a disturbing study revealing the direction
            humanity is headed if AI is allowed to keep evolving,
            unchecked. I wish there were more movies like this masterpiece.
            Sentiment:
            """)
            .options(ChatOptions.builder()
                    .model("claude-3-7-sonnet-latest")
                    .temperature(0.1)
                    .maxTokens(5)
                    .build())
            .call()
            .entity(Sentiment.class);

    System.out.println("Output: " + reviewSentiment);
}
```

Этот пример показывает, как классифицировать настроение рецензии на фильм без предоставления примеров. Обратите внимание на низкую температуру (0.1) для более детерминированных результатов и прямое сопоставление `.entity(Sentiment.class)` с перечислением Java.

**Ссылка:** Brown, T. B., et al. (2020). "Language Models are Few-Shot Learners." arXiv:2005.14165. [https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)

### 2.2 One-Shot & Few-Shot PromptingFew-shot prompting предоставляет модели один или несколько примеров, чтобы помочь направить её ответы, что особенно полезно для задач, требующих специфических форматов вывода. Показывая модели примеры желаемых пар входных и выходных данных, она может изучить шаблон и применить его к новым входным данным без явных обновлений параметров.

One-shot предоставляет один пример, что полезно, когда примеры дороги или когда шаблон относительно прост. Few-shot использует несколько примеров (обычно 3-5), чтобы помочь модели лучше понять шаблоны в более сложных задачах или проиллюстрировать различные варианты правильных выводов.

```java
// Implementation of Section 2.2: One-shot & few-shot (page 16)
public void pt_one_shot_few_shots(ChatClient chatClient) {
    String pizzaOrder = chatClient.prompt("""
            Parse a customer's pizza order into valid JSON

            EXAMPLE 1:
            I want a small pizza with cheese, tomato sauce, and pepperoni.
            JSON Response:
            ```
            {
                "size": "small",
                "type": "normal",
                "ingredients": ["cheese", "tomato sauce", "pepperoni"]
            }
            ```

            EXAMPLE 2:
            Can I get a large pizza with tomato sauce, basil and mozzarella.
            JSON Response:
            ```
            {
                "size": "large",
                "type": "normal",
                "ingredients": ["tomato sauce", "basil", "mozzarella"]
            }
            ```

            Now, I would like a large pizza, with the first half cheese and mozzarella.
            And the other tomato sauce, ham and pineapple.
            """)
            .options(ChatOptions.builder()
                    .model("claude-3-7-sonnet-latest")
                    .temperature(0.1)
                    .maxTokens(250)
                    .build())
            .call()
            .content();
}
```

Few-shot prompting особенно эффективно для задач, требующих специфического форматирования, обработки крайних случаев или когда определение задачи может быть неоднозначным без примеров. Качество и разнообразие примеров значительно влияют на производительность.

**Ссылка:** Brown, T. B., et al. (2020). "Language Models are Few-Shot Learners." arXiv:2005.14165. [https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)

### 2.3 Системное, контекстуальное и ролевое побуждение

#### Системное побуждениеСистемные подсказки задают общий контекст и цель для языковой модели, определяя "большую картину" того, что модель должна делать. Они устанавливают поведенческую структуру, ограничения и высокоуровневые цели для ответов модели, отделяя их от конкретных запросов пользователя.

Системные подсказки действуют как постоянное "заявление о миссии" на протяжении всего разговора, позволяя вам устанавливать глобальные параметры, такие как формат вывода, тон, этические границы или определения ролей. В отличие от пользовательских подсказок, которые сосредоточены на конкретных задачах, системные подсказки формируют то, как все пользовательские подсказки должны интерпретироваться.

```java
// Реализация Раздела 2.3.1: Системные подсказки
public void pt_system_prompting_1(ChatClient chatClient) {
    String movieReview = chatClient
            .prompt()
            .system("Классифицируйте рецензии на фильмы как положительные, нейтральные или отрицательные. Возвращайте только метку в верхнем регистре.")
            .user("""
                    Рецензия: "Она" — это тревожное исследование, показывающее направление,
                    в котором движется человечество, если ИИ будет продолжать развиваться,
                    без контроля. Это так тревожно, что я не смог его посмотреть.

                    Настроение:
                    """)
            .options(ChatOptions.builder()
                    .model("claude-3-7-sonnet-latest")
                    .temperature(1.0)
                    .topK(40)
                    .topP(0.8)
                    .maxTokens(5)
                    .build())
            .call()
            .content();
}
```

Системные подсказки особенно мощны в сочетании с возможностями сопоставления сущностей Spring AI:

```java
// Реализация Раздела 2.3.1: Системные подсказки с выводом в формате JSON
record MovieReviews(Movie[] movie_reviews) {
    enum Sentiment {
        POSITIVE, NEUTRAL, NEGATIVE
    }

    record Movie(Sentiment sentiment, String name) {
    }
}

MovieReviews movieReviews = chatClient
        .prompt()
        .system("""
                Классифицируйте рецензии на фильмы как положительные, нейтральные или отрицательные. Возвращайте
                корректный JSON.
                """)
        .user("""
                Рецензия: "Она" — это тревожное исследование, показывающее направление
                в котором движется человечество, если ИИ будет продолжать развиваться,
                без контроля. Это так тревожно, что я не смог его посмотреть.

                Ответ в формате JSON:
                """)
        .call()
        .entity(MovieReviews.class);
```

Системные подсказки особенно ценны для многократных разговоров, обеспечивая последовательное поведение на протяжении нескольких запросов, и для установления ограничений формата, таких как вывод в формате JSON, которые должны применяться ко всем ответам.

**Ссылка:** OpenAI. (2022). "Системное сообщение." [https://platform.openai.com/docs/guides/chat/introduction](https://platform.openai.com/docs/guides/chat/introduction)

#### Подсказки ролейРолевое побуждение инструктирует модель принимать на себя конкретную роль или личность, что влияет на то, как она генерирует контент. Присваивая модели определенную идентичность, экспертизу или точку зрения, вы можете повлиять на стиль, тон, глубину и оформление ее ответов.

Ролевое побуждение использует способность модели имитировать различные области экспертизы и стили общения. Общие роли включают эксперта (например, "Вы опытный специалист по данным"), профессионала (например, "Действуйте как туристический гид") или стилистического персонажа (например, "Объясните, как будто вы Шекспир").

```java
// Реализация Раздела 2.3.2: Ролевое побуждение
public void pt_role_prompting_1(ChatClient chatClient) {
    String travelSuggestions = chatClient
            .prompt()
            .system("""
                    Я хочу, чтобы вы действовали как туристический гид. Я буду писать вам
                    о своем местоположении, и вы предложите 3 места для посещения рядом
                    со мной. В некоторых случаях я также дам вам тип мест, которые я
                    собираюсь посетить.
                    """)
            .user("""
                    Мое предложение: "Я в Амстердаме и хочу посетить только музеи."
                    Предложения по путешествиям:
                    """)
            .call()
            .content();
}
```

Ролевое побуждение можно улучшить с помощью инструкций по стилю:

```java
// Реализация Раздела 2.3.2: Ролевое побуждение с инструкциями по стилю
public void pt_role_prompting_2(ChatClient chatClient) {
    String humorousTravelSuggestions = chatClient
            .prompt()
            .system("""
                    Я хочу, чтобы вы действовали как туристический гид. Я буду писать вам о
                    своем местоположении, и вы предложите 3 места для посещения рядом со мной в
                    юмористическом стиле.
                    """)
            .user("""
                    Мое предложение: "Я в Амстердаме и хочу посетить только музеи."
                    Предложения по путешествиям:
                    """)
            .call()
            .content();
}
```

Эта техника особенно эффективна для специализированных областей знаний, достижения согласованного тона в ответах и создания более увлекательных, персонализированных взаимодействий с пользователями.

**Ссылка:** Shanahan, M., et al. (2023). "Ролевые игры с большими языковыми моделями." arXiv:2305.16367. [https://arxiv.org/abs/2305.16367](https://arxiv.org/abs/2305.16367)

#### Контекстуальное побуждениеКонтекстное побуждение предоставляет дополнительную информацию модели, передавая параметры контекста. Эта техника обогащает понимание модели конкретной ситуации, позволяя давать более релевантные и адаптированные ответы, не загромождая основную инструкцию.

Предоставляя контекстную информацию, вы помогаете модели понять конкретную область, аудиторию, ограничения или факты, относящиеся к текущему запросу. Это приводит к более точным, актуальным и правильно сформулированным ответам.

```java
// Реализация Раздела 2.3.3: Контекстное побуждение
public void pt_contextual_prompting(ChatClient chatClient) {
    String articleSuggestions = chatClient
            .prompt()
            .user(u -> u.text("""
                    Предложите 3 темы для написания статьи с несколькими строками
                    описания того, что должна содержать эта статья.

                    Контекст: {context}
                    """)
                    .param("context", "Вы пишете для блога о ретро-аркадных видеоиграх 80-х годов."))
            .call()
            .content();
}
```

Spring AI делает контекстное побуждение простым с помощью метода param() для внедрения переменных контекста. Эта техника особенно ценна, когда модели необходимо специфическое знание области, когда нужно адаптировать ответы к конкретным аудиториям или сценариям, а также для обеспечения соответствия ответов определенным ограничениям или требованиям.

**Ссылка:** Liu, P., et al. (2021). "Что делает хорошие примеры в контексте для GPT-3?" arXiv:2101.06804. [https://arxiv.org/abs/2101.06804](https://arxiv.org/abs/2101.06804)

### 2.4 Пошаговое побуждение

Пошаговое побуждение разбивает сложные запросы на более простые шаги, сначала получая базовые знания. Эта техника побуждает модель сначала "отступить" от непосредственного вопроса, чтобы рассмотреть более широкий контекст, основные принципы или общие знания, относящиеся к проблеме, прежде чем обращаться к конкретному запросу.

Разбивая сложные проблемы на более управляемые компоненты и устанавливая базовые знания в первую очередь, модель может предоставить более точные ответы на трудные вопросы.

```java
// Реализация Раздела 2.4: Пошаговое побуждение
public void pt_step_back_prompting(ChatClient.Builder chatClientBuilder) {
    // Установите общие параметры для клиента чата
    var chatClient = chatClientBuilder
            .defaultOptions(ChatOptions.builder()
                    .model("claude-3-7-sonnet-latest")
                    .temperature(1.0)
                    .topK(40)
                    .topP(0.8)
                    .maxTokens(1024)
                    .build())
            .build();

    // Сначала получите высокоуровневые концепции
    String stepBack = chatClient
            .prompt("""
                    На основе популярных шутеров от первого лица, какие
                    5 вымышленных ключевых локаций способствуют созданию
                    сложного и увлекательного сюжетного уровня в видеоигре
                    от первого лица?
                    """)
            .call()
            .content();

    // Затем используйте эти концепции в основной задаче
    String story = chatClient
            .prompt()
            .user(u -> u.text("""
                    Напишите один абзац сюжетной линии для нового уровня
                    шутера от первого лица, который является сложным и
                    увлекательным.

                    Контекст: {step-back}
                    """)
                    .param("step-back", stepBack))
            .call()
            .content();
}
```

Пошаговое побуждение особенно эффективно для задач сложного рассуждения, проблем, требующих специализированных знаний области, и когда вы хотите получить более полные и продуманные ответы, а не немедленные ответы.

**Ссылка:** Zheng, Z., et al. (2023). "Отступите на шаг назад: вызов рассуждений через абстракцию в больших языковых моделях." arXiv:2310.06117. [https://arxiv.org/abs/2310.06117](https://arxiv.org/abs/2310.06117)### 2.5 Цепочка размышлений (CoT)

Подход с использованием цепочки размышлений побуждает модель рассуждать шаг за шагом по проблеме, что улучшает точность при решении сложных задач. Явно прося модель показать свою работу или продумать проблему логическими шагами, вы можете значительно повысить производительность в задачах, требующих многократного рассуждения.

CoT работает, побуждая модель генерировать промежуточные шаги рассуждения перед тем, как выдать окончательный ответ, аналогично тому, как люди решают сложные проблемы. Это делает процесс мышления модели явным и помогает ей приходить к более точным выводам.

```java
// Реализация Раздела 2.5: Цепочка размышлений (CoT) - подход без примеров
public void pt_chain_of_thought_zero_shot(ChatClient chatClient) {
    String output = chatClient
            .prompt("""
                    Когда мне было 3 года, мой партнер был в 3 раза старше меня. Сейчас
                    мне 20 лет. Сколько лет моему партнеру?

                    Давайте подумаем шаг за шагом.
                    """)
            .call()
            .content();
}

// Реализация Раздела 2.5: Цепочка размышлений (CoT) - подход с несколькими примерами
public void pt_chain_of_thought_singleshot_fewshots(ChatClient chatClient) {
    String output = chatClient
            .prompt("""
                    В: Когда моему брату было 2 года, я был вдвое старше его. Сейчас
                    мне 40 лет. Сколько лет моему брату? Давайте подумаем шаг
                    за шагом.
                    О: Когда моему брату было 2 года, мне было 2 * 2 = 4 года.
                    Это разница в возрасте 2 года, и я старше. Сейчас мне 40
                    лет, так что моему брату 40 - 2 = 38 лет. Ответ
                    38.
                    В: Когда мне было 3 года, мой партнер был в 3 раза старше меня. Сейчас,
                    мне 20 лет. Сколько лет моему партнеру? Давайте подумаем шаг
                    за шагом.
                    О:
                    """)
            .call()
            .content();
}
```

Ключевая фраза "Давайте подумаем шаг за шагом" побуждает модель показать свой процесс рассуждения. CoT особенно ценен для математических задач, логических задач и любых вопросов, требующих многократного рассуждения. Это помогает уменьшить количество ошибок, делая промежуточные рассуждения явными.

**Ссылка:** Wei, J., и др. (2022). "Подход с цепочкой размышлений вызывает рассуждения в больших языковых моделях." arXiv:2201.11903. [https://arxiv.org/abs/2201.11903](https://arxiv.org/abs/2201.11903)

### 2.6 СамосогласованностьСамосогласованность включает в себя многократный запуск модели и агрегацию результатов для получения более надежных ответов. Эта техника решает проблему изменчивости выходных данных LLM, выбирая различные пути рассуждений для одной и той же задачи и выбирая наиболее согласованный ответ с помощью голосования большинства.

Генерируя несколько путей рассуждений с различными настройками температуры или выборки, а затем агрегируя окончательные ответы, самосогласованность улучшает точность в сложных задачах рассуждения. Это по сути метод ансамбля для выходных данных LLM.

```java
// Реализация Раздела 2.6: Самосогласованность
public void pt_self_consistency(ChatClient chatClient) {
    String email = """
            Привет,
            Я заметил, что вы используете Wordpress для вашего сайта. Отличная
            система управления контентом с открытым исходным кодом. Я тоже
            использовал её в прошлом. Она предлагает множество отличных
            пользовательских плагинов. И её довольно легко настроить.
            Я заметил ошибку в контактной форме, которая возникает, когда
            вы выбираете поле имени. Посмотрите на прикрепленный скриншот,
            где я ввожу текст в поле имени. Обратите внимание на всплывающее
            окно JavaScript, которое я вызвал.
            Но в остальном это отличный сайт. Мне нравится его читать. Не
            стесняйтесь оставить ошибку на сайте, потому что это дает мне
            больше интересных вещей для чтения.
            С уважением,
            Гарри Хакер.
            """;

    record EmailClassification(Classification classification, String reasoning) {
        enum Classification {
            IMPORTANT, NOT_IMPORTANT
        }
    }

    int importantCount = 0;
    int notImportantCount = 0;

    // Запускаем модель 5 раз с одним и тем же вводом
    for (int i = 0; i < 5; i++) {
        EmailClassification output = chatClient
                .prompt()
                .user(u -> u.text("""
                        Email: {email}
                        Классифицируйте вышеуказанный email как ВАЖНЫЙ или НЕ ВАЖНЫЙ. Давайте
                        подумаем шаг за шагом и объясним почему.
                        """)
                        .param("email", email))
                .options(ChatOptions.builder()
                        .temperature(1.0)  // Более высокая температура для большей вариативности
                        .build())
                .call()
                .entity(EmailClassification.class);

        // Подсчет результатов
        if (output.classification() == EmailClassification.Classification.IMPORTANT) {
            importantCount++;
        } else {
            notImportantCount++;
        }
    }

    // Определение окончательной классификации по голосованию большинства
    String finalClassification = importantCount > notImportantCount ? 
            "ВАЖНЫЙ" : "НЕ ВАЖНЫЙ";
}
```

Самосогласованность особенно ценна для решений с высокими ставками, сложных задач рассуждения и когда вам нужны более уверенные ответы, чем может предоставить один ответ. Компромисс заключается в увеличении вычислительных затрат и задержки из-за нескольких вызовов API.

**Ссылка:** Wang, X., et al. (2022). "Self-Consistency Improves Chain of Thought Reasoning in Language Models." arXiv:2203.11171. [https://arxiv.org/abs/2203.11171](https://arxiv.org/abs/2203.11171)

### 2.7 Дерево Мыслей (ToT)Tree of Thoughts (ToT) — это продвинутая структура рассуждений, которая расширяет Chain of Thought, исследуя несколько путей рассуждений одновременно. Она рассматривает решение проблем как процесс поиска, в котором модель генерирует различные промежуточные шаги, оценивает их перспективность и исследует наиболее многообещающие пути.

Эта техника особенно эффективна для сложных задач с несколькими возможными подходами или когда решение требует изучения различных альтернатив перед нахождением оптимального пути.

[NOTE]
====
Оригинальное руководство по "Prompt Engineering" не предоставляет примеров реализации для ToT, вероятно, из-за его сложности. Ниже приведен упрощенный пример, который демонстрирует основную концепцию.
====

Пример решения игры с использованием ToT:

```java
// Реализация Раздела 2.7: Tree of Thoughts (ToT) - пример решения игры
public void pt_tree_of_thoughts_game(ChatClient chatClient) {
    // Шаг 1: Генерация нескольких начальных ходов
    String initialMoves = chatClient
            .prompt("""
                    Вы играете в шахматы. Доска находится в начальной позиции.
                    Сгенерируйте 3 различных возможных начальных хода. Для каждого хода:
                    1. Опишите ход в алгебраической нотации
                    2. Объясните стратегическое мышление, стоящее за этим ходом
                    3. Оцените силу хода от 1 до 10
                    """)
            .options(ChatOptions.builder()
                    .temperature(0.7)
                    .build())
            .call()
            .content();
    
    // Шаг 2: Оценка и выбор наиболее многообещающего хода
    String bestMove = chatClient
            .prompt()
            .user(u -> u.text("""
                    Проанализируйте эти начальные ходы и выберите самый сильный:
                    {moves}
                    
                    Объясните ваше рассуждение шаг за шагом, учитывая:
                    1. Контроль позиции
                    2. Потенциал развития
                    3. Долгосрочное стратегическое преимущество
                    
                    Затем выберите единственный лучший ход.
                    """).param("moves", initialMoves))
            .call()
            .content();
    
    // Шаг 3: Исследование будущих состояний игры из лучшего хода
    String gameProjection = chatClient
            .prompt()
            .user(u -> u.text("""
                    Исходя из этого выбранного начального хода:
                    {best_move}
                    
                    Проектируйте следующие 3 хода для обоих игроков. Для каждой потенциальной ветви:
                    1. Опишите ход и ответный ход
                    2. Оцените получившуюся позицию
                    3. Определите наиболее многообещающее продолжение
                    
                    Наконец, определите наиболее выгодную последовательность ходов.
                    """).param("best_move", bestMove))
            .call()
            .content();
}
```

**Ссылка:** Yao, S., и др. (2023). "Tree of Thoughts: Deliberate Problem Solving with Large Language Models." arXiv:2305.10601. [https://arxiv.org/abs/2305.10601](https://arxiv.org/abs/2305.10601)

### 2.8 Автоматическая разработка подсказокАвтоматическая инженерия подсказок использует ИИ для генерации и оценки альтернативных подсказок. Эта мета-техника использует саму языковую модель для создания, уточнения и оценки различных вариантов подсказок, чтобы найти оптимальные формулировки для конкретных задач.

Систематически генерируя и оценивая варианты подсказок, APE может находить более эффективные подсказки, чем ручная инженерия, особенно для сложных задач. Это способ использования ИИ для улучшения его собственной производительности.

```java
// Implementation of Section 2.8: Automatic Prompt Engineering
public void pt_automatic_prompt_engineering(ChatClient chatClient) {
    // Generate variants of the same request
    String orderVariants = chatClient
            .prompt("""
                    We have a band merchandise t-shirt webshop, and to train a
                    chatbot we need various ways to order: "One Metallica t-shirt
                    size S". Generate 10 variants, with the same semantics but keep
                    the same meaning.
                    """)
            .options(ChatOptions.builder()
                    .temperature(1.0)  // High temperature for creativity
                    .build())
            .call()
            .content();

    // Evaluate and select the best variant
    String output = chatClient
            .prompt()
            .user(u -> u.text("""
                    Please perform BLEU (Bilingual Evaluation Understudy) evaluation on the following variants:
```
                    {variants}
```

                    Select the instruction candidate with the highest evaluation score.
                    """).param("variants", orderVariants))
            .call()
            .content();
}
```

APE особенно ценна для оптимизации подсказок для производственных систем, решения сложных задач, где ручная инженерия подсказок достигла своих пределов, и для систематического улучшения качества подсказок в масштабах.

**Ссылка:** Zhou, Y., et al. (2022). "Large Language Models Are Human-Level Prompt Engineers." arXiv:2211.01910. [https://arxiv.org/abs/2211.01910](https://arxiv.org/abs/2211.01910)

### 2.9 Кодовые подсказкиCode prompting относится к специализированным техникам для задач, связанных с кодом. Эти техники используют способность LLM понимать и генерировать языки программирования, что позволяет им писать новый код, объяснять существующий код, отлаживать проблемы и переводить между языками.

Эффективное code prompting обычно включает четкие спецификации, соответствующий контекст (библиотеки, фреймворки, руководства по стилю) и иногда примеры аналогичного кода. Настройки температуры, как правило, ниже (0.1-0.3) для более детерминированных выходных данных.

```java
// Implementation of Section 2.9.1: Prompts for writing code
public void pt_code_prompting_writing_code(ChatClient chatClient) {
    String bashScript = chatClient
            .prompt("""
                    Write a code snippet in Bash, which asks for a folder name.
                    Then it takes the contents of the folder and renames all the
                    files inside by prepending the name draft to the file name.
                    """)
            .options(ChatOptions.builder()
                    .temperature(0.1)  // Low temperature for deterministic code
                    .build())
            .call()
            .content();
}

// Implementation of Section 2.9.2: Prompts for explaining code
public void pt_code_prompting_explaining_code(ChatClient chatClient) {
    String code = """
            #!/bin/bash
            echo "Enter the folder name: "
            read folder_name
            if [ ! -d "$folder_name" ]; then
            echo "Folder does not exist."
            exit 1
            fi
            files=( "$folder_name"/* )
            for file in "${files[@]}"; do
            new_file_name="draft_$(basename "$file")"
            mv "$file" "$new_file_name"
            done
            echo "Files renamed successfully."
            """;

    String explanation = chatClient
            .prompt()
            .user(u -> u.text("""
                    Explain to me the below Bash code:
                    ```
                    {code}
                    ```
                    """).param("code", code))
            .call()
            .content();
}

// Implementation of Section 2.9.3: Prompts for translating code
public void pt_code_prompting_translating_code(ChatClient chatClient) {
    String bashCode = """
            #!/bin/bash
            echo "Enter the folder name: "
            read folder_name
            if [ ! -d "$folder_name" ]; then
            echo "Folder does not exist."
            exit 1
            fi
            files=( "$folder_name"/* )
            for file in "${files[@]}"; do
            new_file_name="draft_$(basename "$file")"
            mv "$file" "$new_file_name"
            done
            echo "Files renamed successfully."
            """;

    String pythonCode = chatClient
            .prompt()
            .user(u -> u.text("""
                    Translate the below Bash code to a Python snippet:                        
                    {code}                        
                    """).param("code", bashCode))
            .call()
            .content();
}
```

Code prompting особенно ценен для автоматизированной документации кода, прототипирования, изучения концепций программирования и перевода между языками программирования. Эффективность может быть дополнительно повышена за счет сочетания с такими техниками, как few-shot prompting или chain-of-thought.

**Ссылка:** Chen, M., et al. (2021). "Evaluating Large Language Models Trained on Code." arXiv:2107.03374. [https://arxiv.org/abs/2107.03374](https://arxiv.org/abs/2107.03374)

## ЗаключениеSpring AI предоставляет элегантный Java API для реализации всех основных техник проектирования подсказок. Сочетая эти техники с мощным сопоставлением сущностей и плавным API Spring, разработчики могут создавать сложные приложения с поддержкой ИИ с чистым и поддерживаемым кодом.

Наиболее эффективный подход часто включает в себя сочетание нескольких техник — например, использование системных подсказок с примерами в несколько шагов или цепочку размышлений с ролевыми подсказками. Гибкий API Spring AI делает эти комбинации простыми для реализации.

Для производственных приложений не забудьте:

1. Тестировать подсказки с различными параметрами (температура, top-k, top-p)
2. Рассмотреть возможность использования самосогласованности для критически важных решений
3. Использовать сопоставление сущностей Spring AI для безопасных по типу ответов
4. Применять контекстные подсказки для предоставления специфических для приложения знаний

С этими техниками и мощными абстракциями Spring AI вы можете создать надежные приложения с поддержкой ИИ, которые обеспечивают последовательные и качественные результаты.

## Ссылки

1. Brown, T. B., et al. (2020). "Языковые модели — это обучающиеся с несколькими примерами." arXiv:2005.14165.
2. Wei, J., et al. (2022). "Цепочка размышлений вызывает рассуждения в больших языковых моделях." arXiv:2201.11903.
3. Wang, X., et al. (2022). "Самосогласованность улучшает рассуждения цепочки размышлений в языковых моделях." arXiv:2203.11171.
4. Yao, S., et al. (2023). "Дерево мыслей: целенаправленное решение проблем с помощью больших языковых моделей." arXiv:2305.10601.
5. Zhou, Y., et al. (2022). "Большие языковые модели — это инженеры подсказок на уровне человека." arXiv:2211.01910.
6. Zheng, Z., et al. (2023). "Сделайте шаг назад: вызов рассуждений через абстракцию в больших языковых моделях." arXiv:2310.06117.
7. Liu, P., et al. (2021). "Что делает хорошие примеры в контексте для GPT-3?" arXiv:2101.06804.
8. Shanahan, M., et al. (2023). "Ролевая игра с большими языковыми моделями." arXiv:2305.16367.
9. Chen, M., et al. (2021). "Оценка больших языковых моделей, обученных на коде." arXiv:2107.03374.
10. [Документация Spring AI](https://docs.spring.io/spring-ai/reference/index.html)
11. [Справка по API ChatClient](https://docs.spring.io/spring-ai/reference/api/chatclient.html)
12. [Руководство по проектированию подсказок от Google](https://www.kaggle.com/whitepaper-prompt-engineering)
