# Подсказки

Подсказки — это входные данные, которые направляют модель ИИ для генерации конкретных выходных данных. Дизайн и формулировка этих подсказок значительно влияют на ответы модели.

На самом низком уровне взаимодействия с моделями ИИ в Spring AI работа с подсказками в Spring AI несколько похожа на управление "Представлением" в Spring MVC. Это включает в себя создание обширного текста с заполнителями для динамического контента. Эти заполнители затем заменяются в зависимости от запросов пользователя или другого кода в приложении. Другой аналогией является SQL-запрос, который содержит заполнители для определенных выражений.

По мере развития Spring AI будут введены более высокие уровни абстракции для взаимодействия с моделями ИИ. Основные классы, описанные в этом разделе, можно сравнить с JDBC с точки зрения их роли и функциональности. Класс `ChatModel`, например, аналогичен основной библиотеке JDBC в JDK. Класс `ChatClient` можно сравнить с `JdbcClient`, построенным на основе `ChatModel` и предоставляющим более продвинутые конструкции через `Advisor`, чтобы учитывать прошлые взаимодействия с моделью, дополнять подсказку дополнительными контекстуальными документами и вводить агентное поведение.

Структура подсказок со временем эволюционировала в области ИИ. Изначально подсказки были простыми строками. Со временем они стали включать заполнители для конкретных входных данных, такие как "USER:", которые распознает модель ИИ. OpenAI ввели еще больше структуры в подсказки, классифицируя несколько строк сообщений на различные роли перед их обработкой моделью ИИ.

## Обзор API

### Подсказка

Обычно используется метод `call()` класса `ChatModel`, который принимает экземпляр `Prompt` и возвращает `ChatResponse`.

Класс `Prompt` функционирует как контейнер для организованной серии объектов `Message` и запроса `ChatOptions`. Каждое `Message` воплощает уникальную роль в подсказке, отличаясь по содержанию и намерению. Эти роли могут охватывать различные элементы, от запросов пользователя до ответов, сгенерированных ИИ, и соответствующей фоновой информации. Эта организация позволяет осуществлять сложные и детализированные взаимодействия с моделями ИИ, так как подсказка строится из нескольких сообщений, каждое из которых назначено для выполнения конкретной роли в диалоге.

Ниже приведена сокращенная версия класса Prompt, с опущенными конструкторами и утилитными методами для краткости:

```java
public class Prompt implements ModelRequest<List<Message>> {

    private final List<Message> messages;

    private ChatOptions chatOptions;
}
```

#### Удобные методы

Класс `Prompt` предоставляет несколько удобных методов для доступа к сообщениям по их роли:

**Доступ к одному сообщению:**

- `getUserMessage()`: Возвращает последнее сообщение пользователя в подсказке или пустое `UserMessage`, если такового нет
- `getSystemMessage()`: Возвращает первое системное сообщение в подсказке или пустое `SystemMessage`, если такового нет
- `getLastUserOrToolResponseMessage()`: Возвращает последнее сообщение ответа пользователя или инструмента, полезное для непрерывности разговора

**Доступ к нескольким сообщениям:**

- `getUserMessages()`: Возвращает список всех сообщений пользователя в подсказке, сохраняя их порядок
- `getSystemMessages()`: Возвращает список всех системных сообщений в подсказке, сохраняя их порядок

Эти методы особенно полезны при работе с многоповоротными разговорами или когда необходимо обрабатывать сообщения по роли.

### Сообщение```markdown
Интерфейс `Message` инкапсулирует текстовое содержимое `Prompt`, набор метаданных и категорию, известную как `MessageType`.

Интерфейс определяется следующим образом:

```java
public interface Content {

	String getContent();

	Map<String, Object> getMetadata();
}

public interface Message extends Content {

	MessageType getMessageType();
}
```

Мультимодальные типы сообщений также реализуют интерфейс `MediaContent`, предоставляющий список объектов контента `Media`.

```java
public interface MediaContent extends Content {

	Collection<Media> getMedia();

}
```

Различные реализации интерфейса `Message` соответствуют различным категориям сообщений, которые может обрабатывать модель ИИ. 
Модели различают категории сообщений на основе разговорных ролей.

![Spring AI Message API, width=800, align="center"](spring-ai-message-api.jpg)

Эти роли эффективно отображаются с помощью `MessageType`, как обсуждено ниже.

#### Роли

Каждому сообщению назначается конкретная роль.
Эти роли классифицируют сообщения, уточняя контекст и цель каждого сегмента подсказки для модели ИИ.
Этот структурированный подход улучшает нюансы и эффективность общения с ИИ, так как каждая часть подсказки играет отдельную и четко определенную роль в взаимодействии.

Основные роли:

- Роль системы: Направляет поведение ИИ и стиль ответа, устанавливая параметры или правила для того, как ИИ интерпретирует и отвечает на ввод. Это похоже на предоставление инструкций ИИ перед началом разговора.
- Роль пользователя: Представляет ввод пользователя – их вопросы, команды или утверждения к ИИ. Эта роль является основной, так как она формирует основу ответа ИИ.
- Роль помощника: Ответ ИИ на ввод пользователя. 
Более чем просто ответ или реакция, она важна для поддержания потока разговора. 
Отслеживая предыдущие ответы ИИ (сообщения его 'Роли помощника'), система обеспечивает последовательные и контекстуально релевантные взаимодействия.
Сообщение помощника также может содержать информацию о запросах на вызов функций.
Это как специальная функция в ИИ, используемая при необходимости для выполнения конкретных задач, таких как вычисления, получение данных или другие задачи, выходящие за рамки простого общения.
- Роль инструмента/функции: Роль инструмента/функции сосредоточена на возврате дополнительной информации в ответ на сообщения помощника с вызовом инструмента.

Роли представлены в виде перечисления в Spring AI, как показано ниже:

```java
public enum MessageType {

	USER("user"),

	ASSISTANT("assistant"),

	SYSTEM("system"),

	TOOL("tool");

    ...
}
```

### PromptTemplate
```Ключевым компонентом для шаблонизации запросов в Spring AI является класс `PromptTemplate`, предназначенный для упрощения создания структурированных запросов, которые затем отправляются модели ИИ для обработки.

```java
public class PromptTemplate implements PromptTemplateActions, PromptTemplateMessageActions {

    // Другие методы будут обсуждены позже
}
```

Этот класс использует API `TemplateRenderer` для рендеринга шаблонов. По умолчанию Spring AI использует реализацию `StTemplateRenderer`, основанную на открытом движке https://www.stringtemplate.org/[StringTemplate], разработанном Терренсом Парром. Переменные шаблона определяются синтаксисом `{}`, но вы можете настроить разделители для использования другого синтаксиса.

```java
public interface TemplateRenderer extends BiFunction<String, Map<String, Object>, String> {

	@Override
	String apply(String template, Map<String, Object> variables);

}
```

Spring AI использует интерфейс `TemplateRenderer` для обработки фактической подстановки переменных в строку шаблона. Стандартная реализация использует <<StringTemplate>>. Вы можете предоставить свою собственную реализацию `TemplateRenderer`, если вам нужна пользовательская логика. Для сценариев, где рендеринг шаблона не требуется (например, строка шаблона уже завершена), вы можете использовать предоставленный `NoOpTemplateRenderer`.

.Пример использования пользовательского рендерера StringTemplate с разделителями '<' и '>'
```java
PromptTemplate promptTemplate = PromptTemplate.builder()
    .renderer(StTemplateRenderer.builder().startDelimiterToken('<').endDelimiterToken('>').build())
    .template("""
            Назовите мне названия 5 фильмов, саундтрек к которым был написан <composer>.
            """)
    .build();

String prompt = promptTemplate.render(Map.of("composer", "John Williams"));
```

Интерфейсы, реализованные этим классом, поддерживают различные аспекты создания запросов:

`PromptTemplateStringActions` сосредоточен на создании и рендеринге строк запросов, представляя собой наиболее базовую форму генерации запросов.

`PromptTemplateMessageActions` предназначен для создания запросов через генерацию и манипуляцию объектами `Message`.

`PromptTemplateActions` предназначен для возврата объекта `Prompt`, который может быть передан в `ChatModel` для генерации ответа.

Хотя эти интерфейсы могут не использоваться широко в многих проектах, они демонстрируют различные подходы к созданию запросов.

Реализованные интерфейсы:

```java
public interface PromptTemplateStringActions {

	String render();

	String render(Map<String, Object> model);

}
```

Метод `String render()`: Рендерит шаблон запроса в окончательный строковый формат без внешнего ввода, подходит для шаблонов без заполнителей или динамического контента.

Метод `String render(Map<String, Object> model)`: Расширяет функциональность рендеринга, чтобы включить динамический контент. Он использует `Map<String, Object>`, где ключи карты — это имена заполнителей в шаблоне запроса, а значения — динамический контент, который нужно вставить.

```java
public interface PromptTemplateMessageActions {

	Message createMessage();

    Message createMessage(List<Media> mediaList);

	Message createMessage(Map<String, Object> model);

}
```

Метод `Message createMessage()`: Создает объект `Message` без дополнительных данных, используется для статического или предопределенного содержимого сообщения.

Метод `Message createMessage(List<Media> mediaList)`: Создает объект `Message` со статическим текстовым и медийным содержимым.

Метод `Message createMessage(Map<String, Object> model)`: Расширяет создание сообщений для интеграции динамического контента, принимая `Map<String, Object>`, где каждая запись представляет собой заполнитель в шаблоне сообщения и его соответствующее динамическое значение.

```java
public interface PromptTemplateActions extends PromptTemplateStringActions {

	Prompt create();

	Prompt create(ChatOptions modelOptions);

	Prompt create(Map<String, Object> model);

	Prompt create(Map<String, Object> model, ChatOptions modelOptions);

}
```

Метод `Prompt create()`: Генерирует объект `Prompt` без внешних данных, идеален для статических или предопределенных запросов.

Метод `Prompt create(ChatOptions modelOptions)`: Генерирует объект `Prompt` без внешних данных и с конкретными параметрами для запроса чата.

Метод `Prompt create(Map<String, Object> model)`: Расширяет возможности создания запросов, чтобы включить динамический контент, принимая `Map<String, Object>`, где каждая запись карты является заполнителем в шаблоне запроса и его соответствующим динамическим значением.

Метод `Prompt create(Map<String, Object> model, ChatOptions modelOptions)`: Расширяет возможности создания запросов, чтобы включить динамический контент, принимая `Map<String, Object>`, где каждая запись карты является заполнителем в шаблоне запроса и его соответствующим динамическим значением, а также конкретные параметры для запроса чата.## Пример использования

Простой пример, взятый из [AI Workshop on PromptTemplates](https://github.com/Azure-Samples/spring-ai-azure-workshop/blob/main/2-README-prompt-templating.md), показан ниже.

```java
PromptTemplate promptTemplate = new PromptTemplate("Tell me a {adjective} joke about {topic}");

Prompt prompt = promptTemplate.create(Map.of("adjective", adjective, "topic", topic));

return chatModel.call(prompt).getResult();
```

Другой пример, взятый из [AI Workshop on Roles](https://github.com/Azure-Samples/spring-ai-azure-workshop/blob/main/3-README-prompt-roles.md), показан ниже.

```java
String userText = """
    Tell me about three famous pirates from the Golden Age of Piracy and why they did.
    Write at least a sentence for each pirate.
    """;

Message userMessage = new UserMessage(userText);

String systemText = """
  You are a helpful AI assistant that helps people find information.
  Your name is {name}
  You should reply to the user's request with your name and also in the style of a {voice}.
  """;

SystemPromptTemplate systemPromptTemplate = new SystemPromptTemplate(systemText);
Message systemMessage = systemPromptTemplate.createMessage(Map.of("name", name, "voice", voice));

Prompt prompt = new Prompt(List.of(userMessage, systemMessage));

List<Generation> response = chatModel.call(prompt).getResults();
```

Это показывает, как можно создать экземпляр `Prompt`, используя `SystemPromptTemplate` для создания `Message` с системной ролью, передавая значения-заполнители. Сообщение с ролью `user` затем комбинируется с сообщением роли `system`, чтобы сформировать запрос. Запрос затем передается в ChatModel для получения генеративного ответа.

### Использование пользовательского рендерера шаблонов

Вы можете использовать пользовательский рендерер шаблонов, реализовав интерфейс `TemplateRenderer` и передав его в конструктор `PromptTemplate`. Вы также можете продолжать использовать стандартный `StTemplateRenderer`, но с пользовательской конфигурацией.

По умолчанию переменные шаблона определяются с помощью синтаксиса `{}`. Если вы планируете включить JSON в ваш запрос, вам может понадобиться использовать другой синтаксис, чтобы избежать конфликтов с синтаксисом JSON. Например, вы можете использовать разделители `<` и `>`.

```java
PromptTemplate promptTemplate = PromptTemplate.builder()
    .renderer(StTemplateRenderer.builder().startDelimiterToken('<').endDelimiterToken('>').build())
    .template("""
            Tell me the names of 5 movies whose soundtrack was composed by <composer>.
            """)
    .build();

String prompt = promptTemplate.render(Map.of("composer", "John Williams"));
```

### Использование ресурсов вместо сырых строк

Spring AI поддерживает абстракцию `org.springframework.core.io.Resource`, поэтому вы можете поместить данные запроса в файл, который можно напрямую использовать в `PromptTemplate`. Например, вы можете определить поле в вашем компоненте, управляемом Spring, для получения `Resource`.

```java
@Value("classpath:/prompts/system-message.st")
private Resource systemResource;
```

и затем передать этот ресурс непосредственно в `SystemPromptTemplate`.

```java
SystemPromptTemplate systemPromptTemplate = new SystemPromptTemplate(systemResource);
```

## Инженерия запросовВ генеративном ИИ создание подсказок является важной задачей для разработчиков. Качество и структура этих подсказок значительно влияют на эффективность вывода ИИ. Инвестирование времени и усилий в разработку продуманных подсказок может значительно улучшить результаты работы ИИ.

Обмен и обсуждение подсказок — это распространенная практика в сообществе ИИ. Этот совместный подход не только создает общее учебное пространство, но и приводит к выявлению и использованию высокоэффективных подсказок.

Исследования в этой области часто включают анализ и сравнение различных подсказок для оценки их эффективности в различных ситуациях. Например, одно значительное исследование показало, что начало подсказки с фразы "Сделайте глубокий вдох и работайте над этой задачей шаг за шагом" значительно повысило эффективность решения проблем. Это подчеркивает влияние, которое хорошо подобранный язык может оказать на производительность систем генеративного ИИ.

Понимание наиболее эффективного использования подсказок, особенно с учетом быстрого развития технологий ИИ, является постоянной задачей. Вы должны осознавать важность проектирования подсказок и рассмотреть возможность использования идей из сообщества и исследований для улучшения стратегий создания подсказок.

### Создание эффективных подсказок

При разработке подсказок важно интегрировать несколько ключевых компонентов для обеспечения ясности и эффективности:

- **Инструкции**: Предоставьте четкие и прямые инструкции ИИ, аналогично тому, как вы общались бы с человеком. Эта ясность необходима для того, чтобы помочь ИИ "понять", что ожидается.

- **Внешний контекст**: При необходимости включите соответствующую фоновую информацию или конкретные указания для ответа ИИ. Этот "внешний контекст" формирует подсказку и помогает ИИ понять общую ситуацию.

- **Ввод пользователя**: Это простая часть — прямой запрос или вопрос пользователя, формирующий суть подсказки.

- **Индикатор вывода**: Этот аспект может быть сложным. Он включает в себя указание желаемого формата для ответа ИИ, например, JSON. Однако имейте в виду, что ИИ не всегда будет строго следовать этому формату. Например, он может добавить фразу "вот ваш JSON" перед фактическими данными JSON или иногда сгенерировать структуру, похожую на JSON, которая не является точной.

Предоставление ИИ примеров ожидаемого формата вопроса и ответа может быть очень полезным при создании подсказок. Эта практика помогает ИИ "понять" структуру и намерение вашего запроса, что приводит к более точным и релевантным ответам. Хотя эта документация не углубляется в эти техники, они предоставляют отправную точку для дальнейшего изучения проектирования подсказок ИИ.

Ниже приведен список ресурсов для дальнейшего изучения.

#### Простые техники

- **https://www.promptingguide.ai/introduction/examples.en#text-summarization[Сжатие текста]**: +
Сокращает обширный текст до кратких резюме, захватывая ключевые моменты и основные идеи, при этом опуская менее критические детали.

- **https://www.promptingguide.ai/introduction/examples.en#question-answering[Ответы на вопросы]**: +
Сосредоточен на получении конкретных ответов из предоставленного текста на основе вопросов, заданных пользователем. Это о том, как точно определить и извлечь релевантную информацию в ответ на запросы.

- **https://www.promptingguide.ai/introduction/examples.en#text-classification[Классификация текста]**: +
Систематически классифицирует текст по заранее определенным категориям или группам, анализируя текст и присваивая его наиболее подходящей категории на основе его содержания.

- **https://www.promptingguide.ai/introduction/examples.en#conversation[Разговор]**: +
Создает интерактивные диалоги, в которых ИИ может вести обмен сообщениями с пользователями, имитируя естественный поток разговора.

- **https://www.promptingguide.ai/introduction/examples.en#code-generation[Генерация кода]**: +
Генерирует функциональные фрагменты кода на основе конкретных требований или описаний пользователя, переводя инструкции на естественном языке в исполняемый код.#### Продвинутые техники

- **https://www.promptingguide.ai/techniques/zeroshot[Zero-shot], https://www.promptingguide.ai/techniques/fewshot[Few-shot Learning]**: +
Позволяет модели делать точные предсказания или ответы с минимальным или отсутствующим количеством предварительных примеров конкретного типа задачи, понимая и выполняя новые задачи, используя усвоенные обобщения.

- **https://www.promptingguide.ai/techniques/cot[Chain-of-Thought]**: +
Связывает несколько ответов ИИ, чтобы создать последовательный и контекстуально осведомленный разговор. Это помогает ИИ поддерживать нить обсуждения, обеспечивая актуальность и непрерывность.

- **https://www.promptingguide.ai/techniques/react[ReAct (Reason + Act)]**: +
В этом методе ИИ сначала анализирует (размышляет о) входных данных, а затем определяет наиболее подходящий курс действий или ответ. Он сочетает понимание с принятием решений.

#### Рекомендации Microsoft

- **https://github.com/microsoft/guidance[Framework for Prompt Creation and Optimization]**: +
Microsoft предлагает структурированный подход к разработке и уточнению подсказок. Эта структура направляет пользователей в создании эффективных подсказок, которые вызывают желаемые ответы от моделей ИИ, оптимизируя взаимодействие для ясности и эффективности.

## Токены

Токены имеют важное значение в том, как модели ИИ обрабатывают текст, действуя как мост, который преобразует слова (как мы их понимаем) в формат, который могут обрабатывать модели ИИ. Это преобразование происходит в два этапа: слова преобразуются в токены при вводе, а затем эти токены снова преобразуются в слова в выводе.

Токенизация, процесс разбивки текста на токены, является основополагающей для того, как модели ИИ понимают и обрабатывают язык. Модель ИИ работает с этим токенизированным форматом, чтобы понимать и отвечать на подсказки.

Чтобы лучше понять токены, подумайте о них как о частях слов. Обычно токен представляет собой около трех четвертей слова. Например, полное собрание сочинений Шекспира, состоящее примерно из 900 000 слов, будет переведено в около 1,2 миллиона токенов.

Экспериментируйте с https://platform.openai.com/tokenizer[OpenAI Tokenizer UI], чтобы увидеть, как слова преобразуются в токены.

Токены имеют практические последствия, выходящие за рамки их технической роли в обработке ИИ, особенно в отношении выставления счетов и возможностей модели:

- Выставление счетов: Услуги моделей ИИ часто выставляют счета на основе использования токенов. Как ввод (подсказка), так и вывод (ответ) вносят вклад в общий подсчет токенов, что делает более короткие подсказки более экономичными.

- Ограничения модели: Разные модели ИИ имеют различные ограничения по токенам, определяющие их "контекстное окно" – максимальное количество информации, которое они могут обрабатывать за раз. Например, лимит GPT-3 составляет 4K токенов, в то время как другие модели, такие как Claude 2 и Meta Llama 2, имеют лимиты в 100K токенов, а некоторые исследовательские модели могут обрабатывать до 1 миллиона токенов.

- Контекстное окно: Лимит токенов модели определяет ее контекстное окно. Входные данные, превышающие этот лимит, не обрабатываются моделью. Важно отправлять только минимально эффективный набор информации для обработки. Например, когда вы запрашиваете "Гамлета", нет необходимости включать токены из всех других произведений Шекспира.

- Метаданные ответа: Метаданные ответа от модели ИИ включают количество использованных токенов, что является важной информацией для управления использованием и затратами.
