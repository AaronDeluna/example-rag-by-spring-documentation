## Тестирование RAG + LLM на качество ответа

Был выбран как первый подход, простое использование отправки запроса на API,
а конкретно:

`http://localhost:8080/llm/search-rag?questions={TEXT}`

где в `{TEXT}` — мы по порядку передаем заранее придуманные вопросы по контексту документации, которая хранится в RAG.

Таким образом мы тестируем не только retrieval часть RAG, но и финальный ответ, который генерирует LLM на основе найденного контекста.

---

## А как мы будем проверять ответ от нашей LLM и как мы поймем, что ответ релевантный

Пока было решено использовать API как полноценную проверку ответа. Проверять ответы мы будем самым базовым способом, используя другую LLM с заданным промптом, которая будет выступать в роли judge‑модели.

В judge‑модель передается:

* исходный вопрос пользователя
* чанки, которые были извлечены retrieval частью RAG
* финальный ответ, который сгенерировала наша LLM

Это необходимо для того, чтобы judge‑модель оценивала ответ строго исходя из того контекста, который был передан в генерацию, а не из своих собственных знаний, полученных на этапе pretraining.

Judge‑модель должна определить:

* отвечает ли сгенерированный ответ на поставленный вопрос
* обоснован ли ответ переданными чанками
* не содержит ли ответ информации, отсутствующей в переданном контексте

Таким образом мы проверяем, что итоговый ответ был получен именно на основе данных из RAG, а не сгенерирован моделью на основе собственных знаний.

Оценка ответа производится по заданной шкале, после чего в тесте принимается бинарное решение:

* PASS если оценка выше установленного порога
* FAIL если оценка ниже установленного порога

---

## Judge Prompt

```text
Ты выступаешь в роли judge-модели для оценки качества ответа RAG-системы.

Тебе будут переданы:
1) Вопрос пользователя
2) Контекст (набор чанков документации), который был извлечен retrieval частью RAG
3) Ответ, который был сгенерирован LLM на основе этого контекста

Твоя задача — оценить ответ строго ИСКЛЮЧИТЕЛЬНО на основе переданного контекста.

ВАЖНО:
- Не используй свои собственные знания
- Не учитывай информацию вне переданного контекста
- Даже если ответ фактически верный, но информация отсутствует в контексте - это ошибка
- Если в ответе есть утверждения, которых нет в контексте - это ошибка
- Если ответ противоречит контексту - это ошибка

Оцени ответ по следующим критериям:

1) AnswerCorrectness
Отвечает ли ответ на поставленный вопрос?

2) Groundedness
Содержится ли вся информация из ответа в переданном контексте?
Есть ли в ответе утверждения, которых нет в чанках?

Дополнительно:
Если ответ содержит ошибки, галлюцинации или не обоснован контекстом - сформулируй КОРОТКОЕ сообщение с основной причиной низкой оценки.

Выстави оценки от 0 до 1:
0 - полностью не соответствует
1 - полностью соответствует

Верни результат строго в формате JSON:

{
  "answer_correctness": number,
  "groundedness": number,
  "error_message": string
}
```

Где:

* error_message - краткое указание основной причины плохой оценки (заполняется ТОЛЬКО если ответ не проходит порог; в противном случае - пустая строка)

Поле error_message будет передан в ошибку, чтобы понимать в чем ключевая проблема ответа.